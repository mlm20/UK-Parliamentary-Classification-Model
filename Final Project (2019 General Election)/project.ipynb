{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the probability of a UK Parliamentary constituency voting for the Conservative Party"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as logreg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"combined-dataset-england-only.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the dataset\n",
    "\n",
    "In order to get a better model we want there to be an equal number of consituencies which voted Tory as those who didn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting num of constituencies that voted Tory and for another party\n",
    "total = len(dataset)\n",
    "num_CON = dataset[\"Binary_Con (1 = win)\"].sum()\n",
    "num_notCON = total - num_CON\n",
    "\n",
    "# Adjusting dataset\n",
    "dataset_voteCON = dataset.loc[dataset[\"Binary_Con (1 = win)\"] == 1].sample(num_notCON)\n",
    "dataset_votenotCON = dataset.loc[dataset[\"Binary_Con (1 = win)\"] == 0]\n",
    "\n",
    "resampled_dataset = pd.concat((dataset_voteCON, dataset_votenotCON))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into training, validation, and testing group\n",
    "\n",
    "In order to prevent overfitting the model must be validated and tested on data which it is not trained on. Hence we randomly split the data into 3 subgroups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put 80% of the data into a training set and 20% into a combined testing set\n",
    "resampled_dataset_train, resampled_dataset_splitdata = train_test_split(\n",
    "    resampled_dataset, test_size = 0.2, random_state = 0\n",
    ")\n",
    "\n",
    "# Split the combined testing set into validation and testing sets\n",
    "resampled_dataset_val, resampled_dataset_test = train_test_split(\n",
    "    resampled_dataset_splitdata, test_size = 0.5, random_state = 0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('python-data-science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "658304fd40547ad30e221f1f6824feb4536224b38ad65e65a807dc0873c2e463"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
